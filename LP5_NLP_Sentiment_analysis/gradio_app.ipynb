{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Import the required Libraries\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import transformers\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification, TFAutoModelForSequenceClassification\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**App 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.12.0, however version 3.14.0 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Requirements\n",
    "model_path = \"Eva-Gaga/covid-tweet-sentiment-analysis-roberta_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = \"@user\" if t.startswith(\"@\") and len(t) > 1 else t\n",
    "        t = \"http\" if t.startswith(\"http\") else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# ---- Function to process the input and return prediction\n",
    "def sentiment_analysis(text):\n",
    "    text = preprocess(text)\n",
    "\n",
    "    encoded_input = tokenizer(text, return_tensors = \"pt\") # for PyTorch-based models\n",
    "    output = model(**encoded_input)\n",
    "    scores_ = output[0][0].detach().numpy()\n",
    "    scores_ = softmax(scores_)\n",
    "    \n",
    "    # Format output dict of scores\n",
    "    labels = [\"Negative\", \"Neutral\", \"Positive\"]\n",
    "    scores = {l:float(s) for (l,s) in zip(labels, scores_) }\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ---- Gradio app interface\n",
    "app = gr.Interface(fn = sentiment_analysis,\n",
    "                   inputs = gr.Textbox(\"Write your text or tweet here...\"),\n",
    "                   outputs = \"label\",\n",
    "                   title = \"Sentiment Analysis of Tweets on COVID-19 Vaccines\",\n",
    "                   description  = \"To vaccinate or not? This app analyzes sentiment of text based on tweets tweets about COVID-19 Vaccines using a fine-tuned roBERTA model\",\n",
    "                   interpretation = \"default\",\n",
    "                   examples = [[\"I mean if they immunize my kid with something that won't secretly kill him years down the line then I'm all for it, but I don't trust that\"]]\n",
    "                   )\n",
    "\n",
    "app.launch()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**App 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at Eva-Gaga/covid-tweet-sentiment-analysis-roberta_model were not used when initializing RobertaModel: ['classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at Eva-Gaga/covid-tweet-sentiment-analysis-roberta_model and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'prompt': 'Enter text here:'}\n",
      "  warnings.warn(\n",
      "c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\deprecation.py:43: UserWarning: You have unused kwarg parameters in Textbox, please remove them: {'prompt': 'Predicted sentiment:'}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.12.0, however version 3.14.0 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\routes.py\", line 292, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 1007, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 848, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\selas\\AppData\\Local\\Temp\\ipykernel_21524\\2581791126.py\", line 6, in predict\n",
      "    input_ids = transformers.BertTokenizer.from_pretrained(\"Eva-Gaga/covid-tweet-sentiment-analysis-roberta_model\").encode(inputs, return_tensors=\"pt\")\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 1801, in from_pretrained\n",
      "    return cls._from_pretrained(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 1956, in _from_pretrained\n",
      "    tokenizer = cls(*init_inputs, **init_kwargs)\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\tokenization_bert.py\", line 213, in __init__\n",
      "    if not os.path.isfile(vocab_file):\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\genericpath.py\", line 30, in isfile\n",
      "    st = os.stat(path)\n",
      "TypeError: stat: path should be string, bytes, os.PathLike or integer, not NoneType\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\routes.py\", line 292, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 1007, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 848, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\selas\\AppData\\Local\\Temp\\ipykernel_21524\\2581791126.py\", line 6, in predict\n",
      "    input_ids = transformers.BertTokenizer.from_pretrained(\"Eva-Gaga/covid-tweet-sentiment-analysis-roberta_model\").encode(inputs, return_tensors=\"pt\")\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 1801, in from_pretrained\n",
      "    return cls._from_pretrained(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 1956, in _from_pretrained\n",
      "    tokenizer = cls(*init_inputs, **init_kwargs)\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\tokenization_bert.py\", line 213, in __init__\n",
      "    if not os.path.isfile(vocab_file):\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\genericpath.py\", line 30, in isfile\n",
      "    st = os.stat(path)\n",
      "TypeError: stat: path should be string, bytes, os.PathLike or integer, not NoneType\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'RobertaTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\routes.py\", line 292, in run_predict\n",
      "    output = await app.blocks.process_api(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 1007, in process_api\n",
      "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\blocks.py\", line 848, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\to_thread.py\", line 31, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"C:\\Users\\selas\\AppData\\Local\\Temp\\ipykernel_21524\\2581791126.py\", line 6, in predict\n",
      "    input_ids = transformers.BertTokenizer.from_pretrained(\"Eva-Gaga/covid-tweet-sentiment-analysis-roberta_model\").encode(inputs, return_tensors=\"pt\")\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 1801, in from_pretrained\n",
      "    return cls._from_pretrained(\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py\", line 1956, in _from_pretrained\n",
      "    tokenizer = cls(*init_inputs, **init_kwargs)\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\bert\\tokenization_bert.py\", line 213, in __init__\n",
      "    if not os.path.isfile(vocab_file):\n",
      "  File \"c:\\Users\\selas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\genericpath.py\", line 30, in isfile\n",
      "    st = os.stat(path)\n",
      "TypeError: stat: path should be string, bytes, os.PathLike or integer, not NoneType\n"
     ]
    }
   ],
   "source": [
    "# Load the fine-tuned model from the HF model hub\n",
    "model = transformers.AutoModel.from_pretrained(\"Eva-Gaga/covid-tweet-sentiment-analysis-roberta_model\")\n",
    "\n",
    "# Define a function that takes in input and processes it with the model\n",
    "def predict(inputs):\n",
    "    input_ids = transformers.BertTokenizer.from_pretrained(\"Eva-Gaga/covid-tweet-sentiment-analysis-roberta_model\").encode(inputs, return_tensors=\"pt\")\n",
    "    output = model(input_ids)[0]\n",
    "    return output\n",
    "\n",
    "# Create a Gradio interface for the model\n",
    "app = gr.Interface(fn=predict,\n",
    "                   inputs=gr.Textbox(prompt=\"Enter text here:\"),\n",
    "                   outputs=gr.Textbox(prompt= \"Predicted sentiment:\"),\n",
    "                   title = \"Sentiment Analysis of Tweets on COVID-19 Vaccines\",\n",
    "                   description  = \"To vaccinate or not? This app analyzes sentiment of text based on tweets tweets about COVID-19 Vaccines using a fine-tuned roBERTA model\"\n",
    "                   )\n",
    "\n",
    "# Launch the interface\n",
    "app.launch()\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
